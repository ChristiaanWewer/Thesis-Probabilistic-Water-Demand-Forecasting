{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import os\n",
    "from utils import make_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed data\n",
    "scaler = torch.load('../data/processed/scaler_all.pt')\n",
    "train_dfs = torch.load('../data/processed/train_dfs.pt')\n",
    "val_dfs = torch.load('../data/processed/val_dfs.pt')\n",
    "test_df = torch.load('../data/processed/test_df.pt')\n",
    "df_naive = (pd.read_csv('../data/processed/naive_model_final.csv', index_col=0, parse_dates=True) - scaler.mean_[:-1])/scaler.scale_[:-1]\n",
    "df_naive_test_probabilistic_lower_bound = (pd.read_csv('../data/processed/naive_test_probabilistic_lower_bound_final.csv', index_col=0, parse_dates=True) - scaler.mean_[:-1])/scaler.scale_[:-1]\n",
    "df_naive_test_probabilistic_upper_bound = (pd.read_csv('../data/processed/naive_test_probabilistic_upper_bound_final.csv', index_col=0, parse_dates=True) - scaler.mean_[:-1])/scaler.scale_[:-1]\n",
    "df_naive_train_val_probabilistic_lower_bound = (pd.read_csv('../data/processed/naive_train_val_probabilistic_lower_bound_final.csv', index_col=0, parse_dates=True) - scaler.mean_[:-1])/scaler.scale_[:-1]\n",
    "df_naive_train_val_probabilistic_upper_bound = (pd.read_csv('../data/processed/naive_train_val_probabilistic_upper_bound_final.csv', index_col=0, parse_dates=True) - scaler.mean_[:-1])/scaler.scale_[:-1]\n",
    "DMAs = test_df.columns.tolist()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_val_indexer(indexlist, df, dma):\n",
    "\n",
    "    # function puts the naive model predictions in the tensor format [n, 24], where n is the number of samples\n",
    "    min_index = indexlist[0]\n",
    "    max_index = indexlist[-1]\n",
    "    return torch.Tensor(df.loc[min_index:max_index, dma].copy().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the one-hot encoding for the DMAs\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "dict_one_hot = {}\n",
    "for col in DMAs:\n",
    "    col_name = col[4:5]\n",
    "    for c in classes:\n",
    "        if col_name in c:\n",
    "            ind = classes.index(c)\n",
    "            one_hot = np.zeros(len(classes))\n",
    "            one_hot[ind] = 1\n",
    "            dict_one_hot[col] = one_hot\n",
    "df_one_hot = pd.DataFrame(dict_one_hot, index=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A (1/10)\n",
      "Processing B (2/10)\n"
     ]
    }
   ],
   "source": [
    "# make sequences for each dma, dict version\n",
    "name = '24h_out_all_no_weather'\n",
    "os.makedirs(f'../data/sequences/{name}', exist_ok=True)\n",
    "\n",
    "# placeholder values\n",
    "num_val_seqs = []\n",
    "num_train_seqs = []\n",
    "num_test_seqs = []\n",
    "train_xs, train_ys, train_indices = [], torch.tensor([]), []\n",
    "val_xs, val_ys, val_indices =  [], torch.tensor([]), []\n",
    "test_xs, test_ys, test_indices =  [], torch.tensor([]), []\n",
    "\n",
    "# iterate over the DMAs and turn them into sequences\n",
    "for i, dma in enumerate(DMAs):\n",
    "    dma_name = dma[4:5]\n",
    "    print(f'Processing {dma_name} ({i+1}/{len(DMAs)})')\n",
    "    \n",
    "    static_feature = df_one_hot[dma].to_numpy()\n",
    "\n",
    "    # config of the sequences\n",
    "    dict_config_sequences = {\n",
    "        'historic_sequence_length':     168,\n",
    "        'prediction_sequence_length':   24,\n",
    "        'historic_features':            None,\n",
    "        'future_features':              ['Holidays'],\n",
    "        'future_one_hots':              ['Weekday', 'Hour'],\n",
    "        'historic_one_hots':            ['Weekday', 'Hour'],\n",
    "        'target_feature':               dma,\n",
    "        'static_features':              static_feature,\n",
    "        'include_historic_target':      True,\n",
    "        'return_indices':               True,\n",
    "    }\n",
    "\n",
    "    # make placeholders\n",
    "    train_dma_x, train_dma_y, train_dma_ind =  [],  torch.tensor([]), []\n",
    "    num_train_s_in_loop = []\n",
    "\n",
    "    # make sequences for each of the splits that contain the training data\n",
    "    for train_df in train_dfs:\n",
    "        train_x, train_y, train_ind = make_sequences(\n",
    "            train_df,\n",
    "            **dict_config_sequences\n",
    "            )\n",
    "               \n",
    "        train_dma_x.extend(train_x)\n",
    "        train_dma_y = torch.cat((train_dma_y, train_y))\n",
    "        train_dma_ind.extend(train_ind)\n",
    "        num_train_s_in_loop.append(len(train_x))\n",
    "    num_train_seqs.append(num_train_s_in_loop)\n",
    "    \n",
    "    # save train sequences\n",
    "    torch.save(train_dma_x, f'../data/sequences/{name}/train_x_{name}_{dma_name}.pt')\n",
    "    torch.save(train_dma_y, f'../data/sequences/{name}/train_y_{name}_{dma_name}.pt')\n",
    "    torch.save(train_dma_ind, f'../data/sequences/{name}/train_ind_{name}_{dma_name}.pt')\n",
    "\n",
    "    train_xs.extend(train_dma_x)\n",
    "    train_ys = torch.cat((train_ys, train_dma_y))\n",
    "    train_indices.extend(train_dma_ind)\n",
    "\n",
    "    # make sequences for each of the splits that contain the validation data\n",
    "    val_dma_x, val_dma_y, val_dma_ind = [],  torch.tensor([]), []   \n",
    "    num_val_s_in_loop = []\n",
    "    for val_df in val_dfs:\n",
    "        val_x, val_y, val_ind = make_sequences(\n",
    "            val_df,\n",
    "            **dict_config_sequences\n",
    "            )\n",
    "\n",
    "        val_dma_x.extend(val_x)\n",
    "        val_dma_y = torch.cat((val_dma_y, val_y))\n",
    "        val_dma_ind.extend(val_ind)\n",
    "        num_val_s_in_loop.append(len(val_x))\n",
    "\n",
    "    num_val_seqs.append(num_val_s_in_loop)\n",
    "    val_dma_naive2 = torch.stack([naive_val_indexer(test_index, df_naive, dma) for test_index in val_dma_ind])\n",
    "    val_dma_naive_up = torch.stack([naive_val_indexer(test_index, df_naive_train_val_probabilistic_upper_bound, dma) for test_index in val_dma_ind])\n",
    "    val_dma_naive_low = torch.stack([naive_val_indexer(test_index, df_naive_train_val_probabilistic_lower_bound, dma) for test_index in val_dma_ind])\n",
    "\n",
    "    # save val sequences\n",
    "    torch.save(val_dma_x, f'../data/sequences/{name}/val_x_{name}_{dma_name}.pt')\n",
    "    torch.save(val_dma_y, f'../data/sequences/{name}/val_y_{name}_{dma_name}.pt')\n",
    "    torch.save(val_dma_ind, f'../data/sequences/{name}/val_ind_{name}_{dma_name}.pt')\n",
    "    torch.save(val_dma_naive2, f'../data/sequences/{name}/val_naive_{name}_{dma_name}.pt')\n",
    "    torch.save(val_dma_naive_up, f'../data/sequences/{name}/val_naive_up_{name}_{dma_name}.pt')\n",
    "    torch.save(val_dma_naive_low, f'../data/sequences/{name}/val_naive_low_{name}_{dma_name}.pt')\n",
    "\n",
    "    val_xs.extend(val_dma_x)\n",
    "    val_ys = torch.cat((val_ys, val_dma_y))\n",
    "    val_indices.extend(val_dma_ind)\n",
    "\n",
    "    # make sequences for the test data\n",
    "    test_x, test_y, test_ind = make_sequences(\n",
    "        test_df,\n",
    "        **dict_config_sequences\n",
    "        )\n",
    "    num_test_seqs.append(len(test_x))\n",
    "    \n",
    "    test_naive_2 = torch.stack([naive_val_indexer(test_index, df_naive, dma) for test_index in test_ind])\n",
    "    test_naive_up = torch.stack([naive_val_indexer(test_index, df_naive_test_probabilistic_upper_bound, dma) for test_index in test_ind])\n",
    "    test_naive_low = torch.stack([naive_val_indexer(test_index, df_naive_test_probabilistic_lower_bound, dma) for test_index in test_ind])\n",
    "\n",
    "    # save test sequences\n",
    "    torch.save(test_x, f'../data/sequences/{name}/test_x_{name}_{dma_name}.pt')\n",
    "    torch.save(test_y, f'../data/sequences/{name}/test_y_{name}_{dma_name}.pt')\n",
    "    torch.save(test_ind, f'../data/sequences/{name}/test_ind_{name}_{dma_name}.pt')\n",
    "    torch.save(test_naive_2, f'../data/sequences/{name}/test_naive_final_{name}_{dma_name}.pt')\n",
    "    torch.save(test_naive_up, f'../data/sequences/{name}/test_naive_up_final_{name}_{dma_name}.pt')\n",
    "    torch.save(test_naive_low, f'../data/sequences/{name}/test_naive_low_final_{name}_{dma_name}.pt')\n",
    "\n",
    "    test_xs.extend(test_x)\n",
    "    test_ys = torch.cat((test_ys, test_y))\n",
    "    test_indices.extend(test_ind)\n",
    "\n",
    "torch.save(train_xs, f'../data/sequences/{name}/train_x_{name}_full_sequence.pt')\n",
    "torch.save(train_ys, f'../data/sequences/{name}/train_y_{name}_full_sequence.pt')\n",
    "torch.save(train_indices, f'../data/sequences/{name}/train_ind_{name}_full_sequence.pt')\n",
    "\n",
    "torch.save(val_xs, f'../data/sequences/{name}/val_x_{name}_full_sequence.pt')\n",
    "torch.save(val_ys, f'../data/sequences/{name}/val_y_{name}_full_sequence.pt')\n",
    "torch.save(val_indices, f'../data/sequences/{name}/val_ind_{name}_full_sequence.pt')\n",
    "\n",
    "torch.save(test_xs, f'../data/sequences/{name}/test_x_{name}_full_sequence.pt')\n",
    "torch.save(test_ys, f'../data/sequences/{name}/test_y_{name}_full_sequence.pt')\n",
    "torch.save(test_indices, f'../data/sequences/{name}/test_ind_{name}_full_sequence.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
