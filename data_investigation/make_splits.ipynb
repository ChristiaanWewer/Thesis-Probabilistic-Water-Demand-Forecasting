{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import make_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_inflow = pd.read_excel(r'../data/raw/WDSA/Inflow_Data_4.xlsx', index_col=0, parse_dates=True, date_format='%d/%m/%Y %H:%M')\n",
    "DMAs = df_inflow.columns.to_list()\n",
    "df_holidays = pd.read_csv(r'../data/raw/WDSA/holidays.csv', index_col=0, parse_dates=True)\n",
    "df_holidays = df_holidays.resample('h').ffill()\n",
    "df_inflow = df_inflow.merge(df_holidays, left_index=True, right_index=True, how='left')\n",
    "df_inflow.index = df_inflow.index.tz_localize('CET', ambiguous=\"infer\").tz_convert('UTC')\n",
    "df_train_val = df_inflow[:'2022-03-05']\n",
    "df_test = df_inflow['2022-03-6':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make splits\n",
    "split_len_days = 21\n",
    "\n",
    "val_split_1_start = pd.Timestamp('2021-05-01', tz='UTC')\n",
    "val_split_1_end = val_split_1_start + pd.Timedelta(days=split_len_days)\n",
    "val_split_2_start = pd.Timestamp('2021-08-01', tz='UTC')\n",
    "val_split_2_end = val_split_2_start + pd.Timedelta(days=split_len_days)\n",
    "val_split_3_start = pd.Timestamp('2021-11-01', tz='UTC')\n",
    "val_split_3_end = val_split_3_start + pd.Timedelta(days=split_len_days)\n",
    "val_split_4_start = pd.Timestamp('2022-02-01', tz='UTC')\n",
    "val_split_4_end = val_split_4_start + pd.Timedelta(days=split_len_days)\n",
    "\n",
    "\n",
    "val_splits = [\n",
    "    (val_split_1_start, val_split_1_end),\n",
    "    (val_split_2_start, val_split_2_end),\n",
    "    (val_split_3_start, val_split_3_end),\n",
    "    (val_split_4_start, val_split_4_end)\n",
    "]\n",
    "\n",
    "\n",
    "train_splits = [\n",
    "    (df_train_val.index[0], val_split_1_start),\n",
    "    (val_split_1_end, val_split_2_start),\n",
    "    (val_split_2_end, val_split_3_start),\n",
    "    (val_split_3_end, val_split_4_start),\n",
    "    (val_split_4_end, df_train_val.index[-1])\n",
    "]\n",
    "\n",
    "train_dfs = []\n",
    "val_dfs = []\n",
    "\n",
    "for train_split in train_splits:\n",
    "    train_dfs.append(df_train_val[train_split[0]:train_split[1]])\n",
    "\n",
    "for val_split in val_splits:\n",
    "    val_dfs.append(df_train_val[val_split[0]:val_split[1]])\n",
    "\n",
    "train_dfs_merged = pd.concat(train_dfs)\n",
    "val_dfs_merged = pd.concat(val_dfs)\n",
    "\n",
    "# get train and val data scaled\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_dfs_merged)\n",
    "\n",
    "for i, train_df in enumerate(train_dfs):\n",
    "    train_df = pd.DataFrame(scaler.transform(train_df), columns=train_df.columns, index=train_df.index)\n",
    "    train_dfs[i] = train_df.interpolate(limit=3)\n",
    "\n",
    "for i, val_df in enumerate(val_dfs):\n",
    "    val_df = pd.DataFrame(scaler.transform(val_df), columns=val_df.columns, index=val_df.index)\n",
    "    val_dfs[i] = val_df.interpolate(limit=3)\n",
    "\n",
    "df_test_scaled = pd.DataFrame(scaler.transform(df_test), columns=df_test.columns, index=df_test.index)\n",
    "\n",
    "# # save datasets to disk\n",
    "torch.save(train_dfs, '../data/processed/train_dfs.pt')\n",
    "torch.save(val_dfs, '../data/processed/val_dfs.pt')\n",
    "torch.save(df_test_scaled, '../data/processed/test_df.pt')\n",
    "\n",
    "# save scalers to disk\n",
    "torch.save(scaler, '../data/processed/scaler_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# see how many sequences we can make with the current splits\n",
    "\n",
    "val_xs = []\n",
    "train_xs = []\n",
    "DMAs = val_dfs[0].columns.to_list()\n",
    "test_xs = []\n",
    "for dma in DMAs:\n",
    "    train_dma_x, train_dma_y, train_dma_ind =  [],  torch.tensor([]), []\n",
    "    for train_df in train_dfs:\n",
    "        train_x, train_y, train_ind = make_sequences(\n",
    "            train_df,\n",
    "            historic_sequence_length=168,\n",
    "            prediction_sequence_length=24,\n",
    "            historic_features=None,\n",
    "            future_features=None,\n",
    "            future_one_hots=None,\n",
    "            historic_one_hots=None,\n",
    "            target_feature=dma,\n",
    "            static_features=None,\n",
    "            include_historic_target=True,\n",
    "            return_indices=True,\n",
    "            )\n",
    "        \n",
    "        print('---------------train--------------------')\n",
    "        print('split: ', i+1 ,' ', dma, ' len' , end='')\n",
    "        print(len(train_x))\n",
    "\n",
    "        print('split1 start: ', train_df.index[0], 'split1 end: ', train_df.index[-1])\n",
    "        print('-----------------------------------')\n",
    "        \n",
    "        train_dma_x.extend(train_x)\n",
    "        train_dma_y = torch.cat((train_dma_y, train_y))\n",
    "        train_dma_ind.extend(train_ind)\n",
    "    \n",
    "    train_xs.extend(train_dma_x)\n",
    "    val_dma_x, val_dma_y, val_dma_ind =  [],  torch.tensor([]), []\n",
    "\n",
    "    for i, val_df in enumerate(val_dfs):\n",
    "        val_x, val_y, val_ind = make_sequences(\n",
    "            val_df,\n",
    "            historic_sequence_length=168,\n",
    "            prediction_sequence_length=24,\n",
    "            historic_features=None,\n",
    "            future_features=None,\n",
    "            future_one_hots=None,\n",
    "            historic_one_hots=None,\n",
    "            target_feature=dma,\n",
    "            static_features=None,\n",
    "            include_historic_target=True,\n",
    "            return_indices=True,\n",
    "            )\n",
    "        \n",
    "        print('----------------val-------------------')\n",
    "        print('split: ', i+1 ,' ', dma, ' len' , end='')\n",
    "        print(len(val_x))\n",
    "\n",
    "        print('split1 start: ', val_df.index[0], 'split1 end: ', val_df.index[-1])\n",
    "        print('-----------------------------------')\n",
    "        \n",
    "        val_dma_x.extend(val_x)\n",
    "        val_dma_y = torch.cat((val_dma_y, val_y))\n",
    "        val_dma_ind.extend(val_ind)\n",
    "    val_xs.extend(val_dma_x)\n",
    "\n",
    "    test_x, test_y, test_ind = make_sequences(\n",
    "        df_test_scaled,\n",
    "            historic_sequence_length=168,\n",
    "            prediction_sequence_length=24,\n",
    "            historic_features=None,\n",
    "            future_features=None,\n",
    "            future_one_hots=None,\n",
    "            historic_one_hots=None,\n",
    "            target_feature=dma,\n",
    "            static_features=None,\n",
    "            include_historic_target=True,\n",
    "            return_indices=True,\n",
    "    )\n",
    "    test_xs.extend(test_x)\n",
    "    print('----------------test-------------------')\n",
    "    print('split: ', i+1, ' ', dma, ' len', end='')\n",
    "    print(len(test_x))\n",
    "    print('split1 start: ', df_test_scaled.index[0], 'split1 end: ', df_test_scaled.index[-1])\n",
    "    print('----------------------------------------')\n",
    "\n",
    "\n",
    "len(train_xs), len(val_xs), len(test_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = len(train_xs)+ len(val_xs)+ len(test_xs)\n",
    "print(r'percentage train: {}, percentage val: {}, percentage test: {}'.format(len(train_xs)/total_length*100, len(val_xs)/total_length*100, len(test_xs)/total_length*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
